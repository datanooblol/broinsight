{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4ba2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1ce76",
   "metadata": {},
   "source": [
    "# Using pandas dataframe for profiling data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18772513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broinsight.data_quality.create_profile import create_profile, format_profile\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "profile_dict = create_profile(df)\n",
    "profile_str = format_profile(profile_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2efeb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '**Data Quality Assessment: READY**  \\n\\n**Critical Issues Found:** None – all fields have complete data and no severe inconsistencies.  \\n\\n**Recommended Actions:**  \\n1. **Duplicate Check** – There is one duplicate record (rows\\u202f198\\u202f&\\u202f202).  \\n   - *Option A:* Remove the duplicate to avoid any minor bias.  \\n   - *Option B:* Keep it if the duplicate represents a legitimate repeat visit and you want to preserve frequency.  \\n2. **Skewness Awareness** – The `total_bill`, `tip`, and `size` columns show moderate right‑skewness (skew\\u202f≈\\u202f1.1–1.5).  \\n   - If you plan to use algorithms sensitive to distribution shape (e.g., linear regression, k‑means), consider applying a log or Box‑Cox transform.  \\n   - For tree‑based models (random forest, gradient boosting), the skewness is usually not problematic.  \\n3. **Documentation** – Note the duplicate and skewness in your data dictionary so downstream users are aware.  \\n\\n**Next Steps:**  \\n- Proceed with exploratory data analysis and modeling.  \\n- If you decide to transform skewed variables, validate the impact on model performance.  \\n- Keep an eye on the duplicate in any downstream aggregations to ensure it doesn’t inflate counts.\\n\\n**Overall Recommendation:** The dataset is clean and ready for analysis; the only minor concern is a single duplicate record, which can be handled easily.',\n",
       " 'model_name': 'gpt-oss:latest',\n",
       " 'input_token': 0,\n",
       " 'output_token': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from broinsight.experiment.ollama import LocalOpenAI\n",
    "from broprompt import Prompt\n",
    "\n",
    "model = LocalOpenAI()\n",
    "\n",
    "prompt = Prompt.from_markdown(\"broinsight/prompt_hub/dq_suggestion.md\")\n",
    "question = \"Do we have any concern about this one?\"\n",
    "user_input = \"PROFILE:\\n\\n{profile}\\n\\nUSER_INPUT:\\n\\n{question}\\n\\n\".format(profile=profile_str, question=question)\n",
    "response = model.run(system_prompt=prompt.str, messages=[\n",
    "    model.UserMessage(text=user_input)\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb460c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Quality Assessment: READY**  \n",
      "\n",
      "**Critical Issues Found:** None – all fields have complete data and no severe inconsistencies.  \n",
      "\n",
      "**Recommended Actions:**  \n",
      "1. **Duplicate Check** – There is one duplicate record (rows 198 & 202).  \n",
      "   - *Option A:* Remove the duplicate to avoid any minor bias.  \n",
      "   - *Option B:* Keep it if the duplicate represents a legitimate repeat visit and you want to preserve frequency.  \n",
      "2. **Skewness Awareness** – The `total_bill`, `tip`, and `size` columns show moderate right‑skewness (skew ≈ 1.1–1.5).  \n",
      "   - If you plan to use algorithms sensitive to distribution shape (e.g., linear regression, k‑means), consider applying a log or Box‑Cox transform.  \n",
      "   - For tree‑based models (random forest, gradient boosting), the skewness is usually not problematic.  \n",
      "3. **Documentation** – Note the duplicate and skewness in your data dictionary so downstream users are aware.  \n",
      "\n",
      "**Next Steps:**  \n",
      "- Proceed with exploratory data analysis and modeling.  \n",
      "- If you decide to transform skewed variables, validate the impact on model performance.  \n",
      "- Keep an eye on the duplicate in any downstream aggregations to ensure it doesn’t inflate counts.\n",
      "\n",
      "**Overall Recommendation:** The dataset is clean and ready for analysis; the only minor concern is a single duplicate record, which can be handled easily.\n"
     ]
    }
   ],
   "source": [
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44bf7e",
   "metadata": {},
   "source": [
    "# Using duckdb for profiling data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4120d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from broinsight.data_quality.sql_profile import sql_table_profile, sql_field_profile\n",
    "from broinsight.data_quality.create_profile import format_profile\n",
    "from broinsight.data_quality.criteria import assess_data_quality\n",
    "df = sns.load_dataset('tips')\n",
    "conn = duckdb.connect()\n",
    "conn.register(\"tips\", df)\n",
    "profile_dict = sql_field_profile(conn, \"tips\")\n",
    "dataset_summary = sql_table_profile(conn, \"tips\")\n",
    "dq_summary = assess_data_quality(profile_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460c56ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           data_types  missing_values  missing_values_pct  unique_values  unique_values_pct                                     most_frequent                                                                                                                                                                             statistics\n",
      "total_bill      float               0                 0.0            229               0.94  {13.42: 3, 20.29: 2, 13.0: 2, 7.25: 2, 10.07: 2}  {'min': 3.07, 'max': 50.81, 'mean': 19.79, 'median': 17.8, 'std': 8.9, 'var': 79.25, 'skew': 1.13, 'kurt': 1.22, 'iqr': 10.78, 'cv': 0.45, 'lower_bound': -2.82, 'upper_bound': 40.3}\n",
      "tip             float               0                 0.0            123               0.50     {2.0: 33, 3.0: 23, 4.0: 12, 5.0: 10, 2.5: 10}        {'min': 1.0, 'max': 10.0, 'mean': 3.0, 'median': 2.9, 'std': 1.38, 'var': 1.91, 'skew': 1.47, 'kurt': 3.65, 'iqr': 1.56, 'cv': 0.46, 'lower_bound': -0.34, 'upper_bound': 5.91}\n",
      "sex            string               0                 0.0              2               0.01                       {'Male': 157, 'Female': 87}                                           {'mode': 'Male', 'avg_length': 4.71, 'min_length': 4, 'max_length': 6, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.01}\n",
      "smoker         string               0                 0.0              2               0.01                            {'No': 151, 'Yes': 93}                                             {'mode': 'No', 'avg_length': 2.38, 'min_length': 2, 'max_length': 3, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.01}\n",
      "day            string               0                 0.0              4               0.02     {'Sat': 87, 'Sun': 76, 'Thur': 62, 'Fri': 19}                                            {'mode': 'Sat', 'avg_length': 3.25, 'min_length': 3, 'max_length': 4, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.02}\n",
      "time           string               0                 0.0              2               0.01                      {'Dinner': 176, 'Lunch': 68}                                         {'mode': 'Dinner', 'avg_length': 5.72, 'min_length': 5, 'max_length': 6, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.01}\n",
      "size          integer               0                 0.0              6               0.02                {2: 156, 3: 38, 4: 37, 5: 5, 1: 4}                 {'min': 1, 'max': 6, 'mean': 2.57, 'median': 2.0, 'std': 0.95, 'var': 0.9, 'skew': 1.45, 'kurt': 1.73, 'iqr': 1.0, 'cv': 0.37, 'lower_bound': 0.5, 'upper_bound': 4.5}\n"
     ]
    }
   ],
   "source": [
    "profile_df = pd.DataFrame.from_dict(profile_dict, orient=\"index\")\n",
    "print(profile_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9b14de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dataset Overview\n",
      "**Size:** 244 rows × 7 columns\n",
      "**Duplicates:** 1 duplicate record(s) found\n",
      "\n",
      "# Fields\n",
      "## total_bill\n",
      "**Type:** float\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 229 (94.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.13) (minor)\n",
      "**Stats:** min=3.07, max=50.81, mean=19.79, skew=1.13\n",
      "\n",
      "## tip\n",
      "**Type:** float\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 123 (50.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.47) (minor)\n",
      "**Stats:** min=1.0, max=10.0, mean=3.0, skew=1.47\n",
      "\n",
      "## sex\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Male, avg_length=4.71\n",
      "\n",
      "## smoker\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=No, avg_length=2.38\n",
      "\n",
      "## day\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 4 (2.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Sat, avg_length=3.25\n",
      "\n",
      "## time\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Dinner, avg_length=5.72\n",
      "\n",
      "## size\n",
      "**Type:** integer\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 6 (2.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.45) (minor)\n",
      "**Stats:** min=1, max=6, mean=2.57, skew=1.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = dict(\n",
    "    dataset_summary=dataset_summary,\n",
    "    fields={k: {'profile': v, 'quality': dq_summary[k]['summary']} for k, v in profile_dict.items()}\n",
    ")\n",
    "profile_str = format_profile(profile)\n",
    "print(profile_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89722b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '**Data Quality Assessment:** READY  \\n**Critical Issues Found:** None  \\n\\n**Recommended Actions:**  \\n1. **Duplicate Record** – One duplicate exists (≈0.4\\u202f% of rows).  \\n   - *Action:* Decide whether to keep it (e.g., if it represents a genuine repeat visit) or drop it for a cleaner dataset.  \\n2. **Minor Skewness** – All numeric fields (`total_bill`, `tip`, `size`) show moderate positive skew (1.13–1.47).  \\n   - *Action:* If you plan to use models sensitive to distribution shape (e.g., linear regression, Gaussian‑based clustering), consider a log or Box‑Cox transformation. Otherwise, the skew is acceptable for most machine‑learning or descriptive tasks.  \\n\\n**Next Steps:**  \\n- Proceed with exploratory data analysis and model building.  \\n- If you encounter any modeling issues that hint at distributional assumptions, revisit the skewness handling step.  \\n\\n**Overall Recommendation:**  \\nThe dataset is in good shape for analysis. A single duplicate and minor skewness do not impede typical analyses; address them only if they become relevant to your specific modeling or reporting goals.',\n",
       " 'model_name': 'gpt-oss:latest',\n",
       " 'input_token': 0,\n",
       " 'output_token': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from broinsight.experiment.ollama import LocalOpenAI\n",
    "from broprompt import Prompt\n",
    "\n",
    "model = LocalOpenAI()\n",
    "\n",
    "prompt = Prompt.from_markdown(\"broinsight/prompt_hub/dq_suggestion.md\")\n",
    "question = \"Do we have any concern about this one?\"\n",
    "user_input = \"PROFILE:\\n\\n{profile}\\n\\nUSER_INPUT:\\n\\n{question}\\n\\n\".format(profile=profile_str, question=question)\n",
    "response = model.run(system_prompt=prompt.str, messages=[\n",
    "    model.UserMessage(text=user_input)\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff32ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Quality Assessment:** READY  \n",
      "**Critical Issues Found:** None  \n",
      "\n",
      "**Recommended Actions:**  \n",
      "1. **Duplicate Record** – One duplicate exists (≈0.4 % of rows).  \n",
      "   - *Action:* Decide whether to keep it (e.g., if it represents a genuine repeat visit) or drop it for a cleaner dataset.  \n",
      "2. **Minor Skewness** – All numeric fields (`total_bill`, `tip`, `size`) show moderate positive skew (1.13–1.47).  \n",
      "   - *Action:* If you plan to use models sensitive to distribution shape (e.g., linear regression, Gaussian‑based clustering), consider a log or Box‑Cox transformation. Otherwise, the skew is acceptable for most machine‑learning or descriptive tasks.  \n",
      "\n",
      "**Next Steps:**  \n",
      "- Proceed with exploratory data analysis and model building.  \n",
      "- If you encounter any modeling issues that hint at distributional assumptions, revisit the skewness handling step.  \n",
      "\n",
      "**Overall Recommendation:**  \n",
      "The dataset is in good shape for analysis. A single duplicate and minor skewness do not impede typical analyses; address them only if they become relevant to your specific modeling or reporting goals.\n"
     ]
    }
   ],
   "source": [
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b8d18",
   "metadata": {},
   "source": [
    "# Using duckdb with s3 for data quality profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f02e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_s3_duckdb(key_id=None, secret=None, region='ap-southeast-1', endpoint=None):\n",
    "    \"\"\"Connect DuckDB to S3 with authentication.\n",
    "    \n",
    "    Args:\n",
    "        key_id: AWS access key ID\n",
    "        secret: AWS secret access key  \n",
    "        region: AWS region\n",
    "        endpoint: Custom S3 endpoint (optional)\n",
    "        \n",
    "    Returns:\n",
    "        duckdb.DuckDBPyConnection: Configured connection\n",
    "    \"\"\"\n",
    "    import duckdb\n",
    "    \n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"INSTALL httpfs\")\n",
    "    conn.execute(\"LOAD httpfs\")\n",
    "    \n",
    "    if key_id and secret:\n",
    "        # Manual credentials\n",
    "        secret_sql = f\"\"\"\n",
    "        CREATE OR REPLACE SECRET s3_secret (\n",
    "            TYPE s3,\n",
    "            PROVIDER config,\n",
    "            KEY_ID '{key_id}',\n",
    "            SECRET '{secret}',\n",
    "            REGION '{region}'\n",
    "        )\"\"\"\n",
    "        if endpoint:\n",
    "            secret_sql = secret_sql.replace(\")\", f\", ENDPOINT '{endpoint}')\")\n",
    "        conn.execute(secret_sql)\n",
    "    else:\n",
    "        # Use credential chain (AWS CLI, env vars, etc.)\n",
    "        conn.execute(\"\"\"\n",
    "        CREATE OR REPLACE SECRET s3_secret (\n",
    "            TYPE s3,\n",
    "            PROVIDER credential_chain\n",
    "        )\"\"\")\n",
    "    \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fa0cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'VS1HE1EKZT7VAZTB',\n",
       "  'HostId': 'APi1+VwjKBovUxhte2P98newhgzhjM3/+eaEUXH3mr2Z/FVtAm5Mxvsw2jxVaex5LLjvKdm3cgpaij6tC37mt+P0yo8OksJf',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'APi1+VwjKBovUxhte2P98newhgzhjM3/+eaEUXH3mr2Z/FVtAm5Mxvsw2jxVaex5LLjvKdm3cgpaij6tC37mt+P0yo8OksJf',\n",
       "   'x-amz-request-id': 'VS1HE1EKZT7VAZTB',\n",
       "   'date': 'Wed, 08 Oct 2025 16:26:22 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"21a1749bc760e771c7a011b17e17d17b\"',\n",
       "   'x-amz-checksum-crc32': 'NUN6ig==',\n",
       "   'x-amz-checksum-type': 'FULL_OBJECT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"21a1749bc760e771c7a011b17e17d17b\"',\n",
       " 'ChecksumCRC32': 'NUN6ig==',\n",
       " 'ChecksumType': 'FULL_OBJECT',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import boto3\n",
    "\n",
    "bucket = 'dev-broinsight'\n",
    "\n",
    "df = sns.load_dataset('tips')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.put_object(Bucket=bucket, Key='tips.csv', Body=df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84dc42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "conn = connect_s3_duckdb(key_id=credentials.access_key, secret=credentials.secret_key, region=session.region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af6f292e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>29.03</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>True</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>22.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>True</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>17.82</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Male</td>\n",
       "      <td>False</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>18.78</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>False</td>\n",
       "      <td>Thur</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_bill   tip     sex  smoker   day    time  size\n",
       "0         16.99  1.01  Female   False   Sun  Dinner     2\n",
       "1         10.34  1.66    Male   False   Sun  Dinner     3\n",
       "2         21.01  3.50    Male   False   Sun  Dinner     3\n",
       "3         23.68  3.31    Male   False   Sun  Dinner     2\n",
       "4         24.59  3.61  Female   False   Sun  Dinner     4\n",
       "..          ...   ...     ...     ...   ...     ...   ...\n",
       "239       29.03  5.92    Male   False   Sat  Dinner     3\n",
       "240       27.18  2.00  Female    True   Sat  Dinner     2\n",
       "241       22.67  2.00    Male    True   Sat  Dinner     2\n",
       "242       17.82  1.75    Male   False   Sat  Dinner     2\n",
       "243       18.78  3.00  Female   False  Thur  Dinner     2\n",
       "\n",
       "[244 rows x 7 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute(\"SELECT * from 's3://{bucket}/tips.csv'\".format(bucket=bucket)).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broinsight.data_quality.sql_profile import sql_table_profile, sql_field_profile\n",
    "from broinsight.data_quality.criteria import assess_data_quality\n",
    "\n",
    "s3_path = \"'s3://{bucket}/tips.csv'\".format(bucket=bucket)\n",
    "\n",
    "profile_dict = sql_field_profile(conn, s3_path)\n",
    "dataset_summary = sql_table_profile(conn, s3_path)\n",
    "dq_summary = assess_data_quality(profile_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c434056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           data_types  missing_values  missing_values_pct  unique_values  unique_values_pct                                       most_frequent                                                                                                                                                                             statistics\n",
      "total_bill      float               0                 0.0            229               0.94  {13.42: 3, 10.34: 2, 10.07: 2, 20.69: 2, 18.29: 2}  {'min': 3.07, 'max': 50.81, 'mean': 19.79, 'median': 17.8, 'std': 8.9, 'var': 79.25, 'skew': 1.13, 'kurt': 1.22, 'iqr': 10.78, 'cv': 0.45, 'lower_bound': -2.82, 'upper_bound': 40.3}\n",
      "tip             float               0                 0.0            123               0.50       {2.0: 33, 3.0: 23, 4.0: 12, 2.5: 10, 5.0: 10}        {'min': 1.0, 'max': 10.0, 'mean': 3.0, 'median': 2.9, 'std': 1.38, 'var': 1.91, 'skew': 1.47, 'kurt': 3.65, 'iqr': 1.56, 'cv': 0.46, 'lower_bound': -0.34, 'upper_bound': 5.91}\n",
      "sex            string               0                 0.0              2               0.01                         {'Male': 157, 'Female': 87}                                           {'mode': 'Male', 'avg_length': 4.71, 'min_length': 4, 'max_length': 6, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.01}\n",
      "smoker        unknown               0                 0.0              2               0.01                              {False: 151, True: 93}                                                                                                                                                                                     {}\n",
      "day            string               0                 0.0              4               0.02       {'Sat': 87, 'Sun': 76, 'Thur': 62, 'Fri': 19}                                            {'mode': 'Sat', 'avg_length': 3.25, 'min_length': 3, 'max_length': 4, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.02}\n",
      "time           string               0                 0.0              2               0.01                        {'Dinner': 176, 'Lunch': 68}                                         {'mode': 'Dinner', 'avg_length': 5.72, 'min_length': 5, 'max_length': 6, 'empty_count': 0, 'whitespace_count': 0, 'pattern_consistency': 0.01}\n",
      "size          integer               0                 0.0              6               0.02                  {2: 156, 3: 38, 4: 37, 5: 5, 1: 4}                 {'min': 1, 'max': 6, 'mean': 2.57, 'median': 2.0, 'std': 0.95, 'var': 0.9, 'skew': 1.45, 'kurt': 1.73, 'iqr': 1.0, 'cv': 0.37, 'lower_bound': 0.5, 'upper_bound': 4.5}\n"
     ]
    }
   ],
   "source": [
    "profile_df = pd.DataFrame.from_dict(profile_dict, orient=\"index\")\n",
    "print(profile_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db916ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dataset Overview\n",
      "**Size:** 244 rows × 7 columns\n",
      "**Duplicates:** 1 duplicate record(s) found\n",
      "\n",
      "# Fields\n",
      "## total_bill\n",
      "**Type:** float\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 229 (94.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.13) (minor)\n",
      "**Stats:** min=3.07, max=50.81, mean=19.79, skew=1.13\n",
      "\n",
      "## tip\n",
      "**Type:** float\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 123 (50.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.47) (minor)\n",
      "**Stats:** min=1.0, max=10.0, mean=3.0, skew=1.47\n",
      "\n",
      "## sex\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Male, avg_length=4.71\n",
      "\n",
      "## smoker\n",
      "**Type:** unknown\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "\n",
      "## day\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 4 (2.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Sat, avg_length=3.25\n",
      "\n",
      "## time\n",
      "**Type:** string\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 2 (1.0%)\n",
      "**Quality:** good\n",
      "**Stats:** mode=Dinner, avg_length=5.72\n",
      "\n",
      "## size\n",
      "**Type:** integer\n",
      "**Missing:** 0 (0.0%)\n",
      "**Unique:** 6 (2.0%)\n",
      "**Quality:** good\n",
      "**Issues:**\n",
      "  - Moderately skewed distribution (skew: 1.45) (minor)\n",
      "**Stats:** min=1, max=6, mean=2.57, skew=1.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profile = dict(\n",
    "    dataset_summary=dataset_summary,\n",
    "    fields={k: {'profile': v, 'quality': dq_summary[k]['summary']} for k, v in profile_dict.items()}\n",
    ")\n",
    "profile_str = format_profile(profile)\n",
    "print(profile_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a13f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '**Data Quality Assessment: READY**\\n\\n**Critical Issues Found:** None – all fields have no missing data, appropriate types, and “good” quality ratings.\\n\\n**Recommended Actions:**\\n\\n1. **Duplicate Record**  \\n   - *What to do:* Verify whether the single duplicate row is truly redundant or represents a legitimate repeat observation.  \\n   - *If redundant:* Drop it to keep the dataset size accurate.  \\n   - *If legitimate:* Keep it and document that it represents a repeated visit.\\n\\n2. **Moderately Skewed Distributions**  \\n   - *Fields affected:* `total_bill`, `tip`, and `size`.  \\n   - *Impact:* Minor skewness is unlikely to distort most descriptive or classification tasks. However, if you plan to use models that assume normality (e.g., linear regression, ANOVA) or perform statistical tests that are sensitive to distribution shape, consider a log or Box–Cox transformation for these columns.\\n\\n3. **Documentation**  \\n   - Record the duplicate handling decision and any transformations applied so future users can understand the preprocessing steps.\\n\\n**Next Steps:**  \\n- Proceed with exploratory data analysis and modeling.  \\n- Keep an eye on the duplicate and skewness during modeling—check residuals or model diagnostics to confirm no adverse effects.\\n\\n**Overall Recommendation:**  \\nThe dataset is in good shape for analysis. Address the single duplicate and optionally transform skewed numeric fields if your analysis requires normality. After that, you’re ready to move forward.',\n",
       " 'model_name': 'gpt-oss:latest',\n",
       " 'input_token': 0,\n",
       " 'output_token': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from broinsight.experiment.ollama import LocalOpenAI\n",
    "from broprompt import Prompt\n",
    "\n",
    "model = LocalOpenAI()\n",
    "\n",
    "prompt = Prompt.from_markdown(\"broinsight/prompt_hub/dq_suggestion.md\")\n",
    "question = \"Do we have any concern about this one?\"\n",
    "user_input = \"PROFILE:\\n\\n{profile}\\n\\nUSER_INPUT:\\n\\n{question}\\n\\n\".format(profile=profile_str, question=question)\n",
    "response = model.run(system_prompt=prompt.str, messages=[\n",
    "    model.UserMessage(text=user_input)\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Quality Assessment: READY**\n",
      "\n",
      "**Critical Issues Found:** None – all fields have no missing data, appropriate types, and “good” quality ratings.\n",
      "\n",
      "**Recommended Actions:**\n",
      "\n",
      "1. **Duplicate Record**  \n",
      "   - *What to do:* Verify whether the single duplicate row is truly redundant or represents a legitimate repeat observation.  \n",
      "   - *If redundant:* Drop it to keep the dataset size accurate.  \n",
      "   - *If legitimate:* Keep it and document that it represents a repeated visit.\n",
      "\n",
      "2. **Moderately Skewed Distributions**  \n",
      "   - *Fields affected:* `total_bill`, `tip`, and `size`.  \n",
      "   - *Impact:* Minor skewness is unlikely to distort most descriptive or classification tasks. However, if you plan to use models that assume normality (e.g., linear regression, ANOVA) or perform statistical tests that are sensitive to distribution shape, consider a log or Box–Cox transformation for these columns.\n",
      "\n",
      "3. **Documentation**  \n",
      "   - Record the duplicate handling decision and any transformations applied so future users can understand the preprocessing steps.\n",
      "\n",
      "**Next Steps:**  \n",
      "- Proceed with exploratory data analysis and modeling.  \n",
      "- Keep an eye on the duplicate and skewness during modeling—check residuals or model diagnostics to confirm no adverse effects.\n",
      "\n",
      "**Overall Recommendation:**  \n",
      "The dataset is in good shape for analysis. Address the single duplicate and optionally transform skewed numeric fields if your analysis requires normality. After that, you’re ready to move forward.\n"
     ]
    }
   ],
   "source": [
    "print(response['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e51fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "broinsight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
